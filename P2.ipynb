{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project 2: **Advanced Lane Finding** \n",
    "***\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in a Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in an image\n",
    "image = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "\n",
    "#printing out some stats and plotting\n",
    "print('This image is:', type(image), 'with dimensions:', image.shape)\n",
    "plt.imshow(image)  # if you wanted to show a single color channel image called 'gray', for example, call as plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions from Project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"\n",
    "    Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    (assuming your grayscaled image is called 'gray')\n",
    "    you should call plt.imshow(gray, cmap='gray')\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    masked_color = np.dstack((masked_image, masked_image, masked_image)) * 255\n",
    "    \n",
    "    return masked_image, masked_color\n",
    "\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + γ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration\n",
    "### Extract Chessboard Corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "nrows = 6\n",
    "ncols = 9\n",
    "objp = np.zeros((nrows*ncols,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:ncols, 0:nrows].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (ncols,nrows), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (ncols,nrows), corners, ret)\n",
    "        #write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "        #cv2.imwrite(write_name, img)\n",
    "        # \n",
    "        #Uncomment the two lines below to view the result\n",
    "        #cv2.imshow('img', img)\n",
    "        #cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Camera Calibration Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# Test undistortion on an image\n",
    "img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "cv2.imwrite('output_images/undistorted_chessboard.jpg',dst)\n",
    "\n",
    "# Save the camera calibration result for later use\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"camera_cal/wide_dist_pickle.p\", \"wb\" ) )\n",
    "#dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivation of polynomial transformation from image coordinates to real coordinates\n",
    "\n",
    "While most of the content in the helper functions is based on code and theory described in the lessons,\n",
    "it might be useful to describe the logic used to tranform polynomials from the image coordinates to the\n",
    "real coordinates since this was not explicitly described in the course lessons. This section therefore,\n",
    "provides a brief description of the approach used to perform the tranformation.\n",
    "\n",
    "Let the equation of the polynomial in the image coordinates be:\n",
    "\n",
    "\\begin{equation}\n",
    "x_i = A_i y_i^{2} + B_i y_i + C_i\n",
    "\\end{equation}\n",
    "\n",
    "In the above equation, $x$ is the dependent variable and $y$ is the independent\n",
    "variable. Let the equation of the corresponding polynomial in the real coordinates be:\n",
    "\n",
    "\\begin{equation}\n",
    "x_r = A_r y_r^{2} + B_r y_r + C_r\n",
    "\\end{equation}\n",
    "\n",
    "Let $\\lambda_x$ and $\\lambda_y$ be the $x$ and $y$ distances (in meters) per pixel. The $x$ and $y$\n",
    "coordinates can therefore be transformed as:\n",
    "\n",
    "\\begin{equation}\n",
    "x_r = \\lambda_{x} x_i  \\\\\n",
    "y_r = \\lambda_{y} x_i \n",
    "\\end{equation}\n",
    "\n",
    "If we substitute the above equations in to the polynomial expression in\n",
    "real coordinates, we get:\n",
    "\n",
    "\\begin{equation}\n",
    "x_i \\lambda_x = A_i\\lambda_y^2 y_i^{2} + B_i \\lambda_y y_i + C_i \\\\\n",
    "x_i = \\frac{A_i\\lambda_y^{2}}{\\lambda_x} y_i^{2} + \\frac{B_i \\lambda_y}{\\lambda_x} y_i + \\frac{C_i}{\\lambda_x}\n",
    "\\end{equation}\n",
    "\n",
    "Comparing the above equation with the equation for the image coordinates and equating the coefficients, we get:\n",
    "\n",
    "\\begin{equation}\n",
    "A_r = \\frac{A_i\\lambda_y^{2}}{\\lambda_x} \\\\\n",
    "B_r = \\frac{B_i \\lambda_y}{\\lambda_x} \\\\\n",
    "C_r = \\frac{C_i}{\\lambda_x}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_thresholds(img):\n",
    "    # Extract R-channel\n",
    "    R = img[:,:,0]\n",
    "\n",
    "    # Extract S-channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # Grayscale image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "    # Threshold x gradient\n",
    "    thresh_min = 50\n",
    "    thresh_max = 100\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    \n",
    "    # Threshold R channel\n",
    "    thresh_R = (150, 255)\n",
    "    binary_R = np.zeros_like(R)\n",
    "    binary_R[(R > thresh_R[0]) & (R <= thresh_R[1])] = 1\n",
    "    \n",
    "    # Threshold S channel\n",
    "    s_thresh_min = 100\n",
    "    s_thresh_max = 255\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
    "\n",
    "    # Combine multiple binary images\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[((s_binary == 1) & binary_R == 1) | (sxbinary == 1) ] = 1\n",
    "    #combined_binary[((s_binary == 1) & binary_R == 1)] = 1\n",
    "    #combined_binary[((s_binary == 1)) | (sxbinary == 1) ] = 1\n",
    "\n",
    "    color_image = np.dstack((combined_binary, combined_binary, combined_binary)) * 255\n",
    "    return binary_R, s_binary, sxbinary, combined_binary, color_image\n",
    "\n",
    "def topview(image):\n",
    "    \"\"\"\n",
    "    Perform perspective transformation to obtain a top view of the image\n",
    "    \"\"\"\n",
    "    \n",
    "    src = np.float32([[600, 444], [675, 444], [1041, 676], [268, 676]])\n",
    "    offsetv = 0\n",
    "    offseth = 300\n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "    dst = np.float32([[offseth, offsetv], [img_size[0]-offseth, offsetv], \n",
    "                                     [img_size[0]-offseth, img_size[1]-offsetv], \n",
    "                                     [offseth, img_size[1]-offsetv]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(image, M, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped, M, Minv\n",
    "\n",
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "\n",
    "    # Fit a second order polynomial to each with np.polyfit() ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    \n",
    "    #Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    middle_fitx = 0.5*(left_fitx + right_fitx)\n",
    "    middle_fit = np.polyfit(middle_fitx, ploty, 2)\n",
    "    \n",
    "    return left_fitx, right_fitx, middle_fitx, ploty, left_fit, right_fit, middle_fit\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    \n",
    "    # Create an output image to draw on and visualize the result\n",
    "    stacked_windows_image = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(stacked_windows_image,(win_xleft_low,win_y_low),\n",
    "                              (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(stacked_windows_image,(win_xright_low,win_y_low),\n",
    "                              (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        #If number of pixes in windows exceeds minpix pixels, recenter next window\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "    \n",
    "    stacked_windows_image[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    stacked_windows_image[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, left_lane_inds, right_lane_inds, stacked_windows_image\n",
    "\n",
    "def search_around_poly(binary_warped):\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Extract the lane points\n",
    "    leftx, lefty, rightx, righty, left_lane_inds, right_lane_inds, stacked_windows_image = find_lane_pixels(binary_warped)\n",
    "        \n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, middle_fitx, ploty, left_fit, right_fit, middle_fit = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    binary_warped_color = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(binary_warped_color)\n",
    "    \n",
    "    # Identify the region between the left and right lanes\n",
    "    left_region_limits = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    right_region_limits = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    region_pts = np.hstack((left_region_limits, right_region_limits))\n",
    "\n",
    "    # Draw the polynomial fit for middle lane line\n",
    "    mid_lower_limits = np.array([np.transpose(np.vstack([middle_fitx-5, ploty]))])\n",
    "    mid_upper_limits = np.array([np.flipud(np.transpose(np.vstack([middle_fitx+5, ploty])))])\n",
    "    mid_region_pts = np.hstack((mid_lower_limits, mid_upper_limits))\n",
    "\n",
    "    # Draw the polynomial fit for left lane line\n",
    "    left_lower_limits = np.array([np.transpose(np.vstack([left_fitx-5, ploty]))])\n",
    "    left_upper_limits = np.array([np.flipud(np.transpose(np.vstack([left_fitx+5, ploty])))])\n",
    "    left_region_pts = np.hstack((left_lower_limits, left_upper_limits))\n",
    "    \n",
    "    # Draw the polynomial fit for right lane line\n",
    "    right_lower_limits = np.array([np.transpose(np.vstack([right_fitx-5, ploty]))])\n",
    "    right_upper_limits = np.array([np.flipud(np.transpose(np.vstack([right_fitx+5, ploty])))])\n",
    "    right_region_pts = np.hstack((right_lower_limits, right_upper_limits))\n",
    "    \n",
    "    # Write left, middle and right polynomial fits to image using different colors\n",
    "    cv2.fillPoly(stacked_windows_image, np.int_([mid_region_pts]), (255,255, 0)) #yellow\n",
    "    cv2.fillPoly(stacked_windows_image, np.int_([left_region_pts]), (255, 105, 180)) #pink\n",
    "    cv2.fillPoly(stacked_windows_image, np.int_([right_region_pts]), (128, 0, 128)) #purple \n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([region_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(binary_warped_color, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    # Draw the lane onto the warped blank image  \n",
    "    result[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    result[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    return result, stacked_windows_image, left_fit, right_fit, middle_fit, \\\n",
    "                                          left_fitx, right_fitx, middle_fitx, ploty\n",
    "\n",
    "def convert_to_real(poly_fit, xm_per_pix, ym_per_pix, poly_degree):\n",
    "    \"\"\"\n",
    "    Convert from image coordinates to real coordinates using scaling factors\n",
    "    \"\"\"\n",
    "    poly_fit_real = [0.0] * (poly_degree+1)\n",
    "\n",
    "    for d in range(poly_degree+1):\n",
    "        poly_fit_real[d] = poly_fit[d] * xm_per_pix / (ym_per_pix ** (poly_degree - d))\n",
    "\n",
    "        return poly_fit_real\n",
    "\n",
    "def measure_curvature(poly_fit, y_eval):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial given the polynomial coefficients\n",
    "    '''\n",
    "    poly_curverad = ((1.0 + (2.0*poly_fit[0]*y_eval + poly_fit[1])**2)**1.5)/(2.0*poly_fit[0])\n",
    "    \n",
    "    return poly_curverad\n",
    "\n",
    "def process_single_image(image, write_to_file = False):\n",
    "    alpha = 1\n",
    "    beta = 1\n",
    "    gamma = 0\n",
    "    \n",
    "    # Specify corners of the quadrilateral masked region of interest\n",
    "    imshape = image.shape\n",
    "    mask_vertices = np.array([[(0.05*imshape[1],imshape[0]),\n",
    "                      (0.47*imshape[1], 0.6*imshape[0]), \n",
    "                      (0.53*imshape[1], 0.6*imshape[0]), \n",
    "                      (0.95*imshape[1], imshape[0])]], dtype=np.int32)\n",
    "    \n",
    "    # Pixel to real world conversion factors\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension    \n",
    "\n",
    "    # Write the original image to disk for reference\n",
    "    if write_to_file:\n",
    "        cv2.imwrite('output_images/original_image.png', cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    " \n",
    "    # Undistort the original image by applying camera calibrtion matrix\n",
    "    undst = cv2.undistort(image, mtx, dist, None, mtx) \n",
    "    if write_to_file:\n",
    "        cv2.imwrite('output_images/undistorted.png', cv2.cvtColor(undst, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    # Use a combination of thresholds and color gradients to obtain an image\n",
    "    # that retains the lane edges while eliminating irrelevant edges as much as possible\n",
    "    binary_R, s_binary, sxbinary, edges_binary, edges_color = edge_thresholds(undst)\n",
    "    if write_to_file:\n",
    "        cv2.imwrite('output_images/edges.png', edges_color)\n",
    "        R_color = np.dstack((binary_R, binary_R, binary_R))*255\n",
    "        s_color = np.dstack((s_binary, s_binary, s_binary))*255\n",
    "        sx_color = np.dstack((sxbinary, sxbinary, sxbinary))*255\n",
    "        cv2.imwrite('output_images/R.jpg', R_color)\n",
    "        cv2.imwrite('output_images/s.jpg', s_color)\n",
    "        cv2.imwrite('output_images/sx.jpg', sx_color)\n",
    "\n",
    "    # Remove all edges outside the region of interest defined by the vertices\n",
    "    masked_image, masked_color = region_of_interest(edges_binary, mask_vertices)    \n",
    "    if write_to_file:\n",
    "        cv2.imwrite('output_images/masked_image.png', masked_color)\n",
    "    \n",
    "    # Transform the masked image to obtain a top view of the image through perspective transform\n",
    "    topview_image, M, Minv = topview(masked_image)\n",
    "    topview_color = np.dstack((topview_image, topview_image, topview_image)) * 255\n",
    "    if write_to_file:\n",
    "        cv2.imwrite('output_images/topview.png', topview_color)\n",
    "    \n",
    "    # Search the top view image to identify the lane region and fit polynomials to\n",
    "    # the left, right and middle of the lane\n",
    "    topview_region, stacked_windows_image, left_fit, right_fit, middle_fit, \\\n",
    "            left_fitx, right_fitx, middle_fitx, ploty = search_around_poly(topview_image)\n",
    "    if write_to_file:\n",
    "        cv2.imwrite('output_images/topview_region.png', topview_region) \n",
    "        cv2.imwrite('output_images/windowed_image.png', cv2.cvtColor(stacked_windows_image, cv2.COLOR_RGB2BGR))    \n",
    "\n",
    "    # Convert polynomial coefficients from image to real coordinate system\n",
    "    left_fit_real = convert_to_real(left_fit, xm_per_pix, ym_per_pix, 2)\n",
    "    right_fit_real = convert_to_real(right_fit, xm_per_pix, ym_per_pix, 2)\n",
    "    middle_fit_real = convert_to_real(middle_fit, xm_per_pix, ym_per_pix, 2)\n",
    "    \n",
    "    # Compute curvature for left, right and middle lines\n",
    "    left_curverad = measure_curvature(left_fit_real, (image.shape[0])*ym_per_pix)\n",
    "    right_curverad = measure_curvature(right_fit_real, (image.shape[0])*ym_per_pix)    \n",
    "    middle_curverad = measure_curvature(middle_fit_real, (image.shape[0])*ym_per_pix)    \n",
    "    \n",
    "    if False:\n",
    "        print('Left lane curvature (m) = ', left_curverad)\n",
    "        print('Right lane curvature (m) = ', right_curverad)\n",
    "        print('Middle lane curvature (m) = ', middle_curverad)\n",
    "    \n",
    "    # Transform the warped image back into the original image\n",
    "    warped_back = cv2.warpPerspective(topview_region, Minv, topview_region.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    if write_to_file:\n",
    "        cv2.imwrite('output_images/lane_region.png', cv2.cvtColor(warped_back, cv2.COLOR_RGB2BGR))    \n",
    "    \n",
    "    # Compute mid point of the lane\n",
    "    mid_lane = np.array([[middle_fitx[-1], ploty[-1]]], dtype = \"float32\")\n",
    "    mid_lane = np.array([mid_lane])\n",
    "    midpoint_lane = cv2.perspectiveTransform(mid_lane, Minv)\n",
    "    \n",
    "    # Compute midpoint of the image (assume this is the center of the car)\n",
    "    mid_image = np.array([[image.shape[1]//2, ploty[-1]]], dtype = \"float32\")\n",
    "    mid_image = np.array([mid_image])\n",
    "    midpoint_image = cv2.perspectiveTransform(mid_image, Minv)\n",
    "    offset = (midpoint_lane[0][0][0] - midpoint_image[0][0][0])*xm_per_pix\n",
    "\n",
    "    # Combined the lane region markings to the original image\n",
    "    result = weighted_img(warped_back, image, alpha, 1, gamma)\n",
    "    if write_to_file:\n",
    "        cv2.imwrite('output_images/weighted_image.png', cv2.cvtColor(result, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "    # Write radius of curvature and offset onto the image\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    radius_loc = (int(0.1*image.shape[0]),int(0.05*image.shape[1]))\n",
    "    offset_loc = (int(0.1*image.shape[0]),int(0.1*image.shape[1]))\n",
    "    fontScale = 1.5\n",
    "    fontColor = (255,255,255)\n",
    "    lineType = 2\n",
    "    radius_text = 'Radius of curvature = ' + str(middle_curverad) + '(m)'\n",
    "    if offset > 0:\n",
    "        offset_text = 'Vehicle is {0:0.2f}m right of center'.format(offset)\n",
    "    else:\n",
    "        offset_text = 'Vehicle is {0:0.2f}m left of center'.format(-offset)\n",
    "\n",
    "    cv2.putText(result,radius_text, radius_loc, font, fontScale, fontColor, lineType)\n",
    "    cv2.putText(result, offset_text, offset_loc, font, fontScale, fontColor, lineType)    \n",
    "    if write_to_file:\n",
    "        cv2.imwrite('output_images/annotated_image.png', cv2.cvtColor(result, cv2.COLOR_RGB2BGR))    \n",
    "    \n",
    "    return result    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for imgpath in os.listdir(\"test_images/\"):\n",
    "for imgpath in [\"straight_lines1.jpg\"]:\n",
    "    fullpath = os.path.join(\"test_images\", imgpath)\n",
    "    basename, ext = os.path.splitext(imgpath)\n",
    "    imgpath_output = basename + '_output' + ext\n",
    "    fullpath_output = os.path.join(\"output_images\", imgpath_output)\n",
    "    \n",
    "    image = mpimg.imread(fullpath)\n",
    "    result = process_single_image(image, write_to_file = True)\n",
    "    \n",
    "    cv2.imwrite(fullpath_output, cv2.cvtColor(result, cv2.COLOR_RGB2BGR))\n",
    "    plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process video by proecessing the individual images that constitute the video\n",
    "video_input = 'project_video.mp4'\n",
    "video_output = 'output_images/project_video_output.mp4'\n",
    "clip1 = VideoFileClip(video_input).subclip(0, None)\n",
    "project_clip = clip1.fl_image(process_single_image) #NOTE: this function expects color images!!\n",
    "%time project_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed video\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
